{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OplHUsyYwLzr",
        "outputId": "1dee00b2-ad22-4e91-8b27-f3cb5748fbfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Ignored the following yanked versions: 8.0.129, 8.0.174, 8.0.177, 8.1.21, 8.1.31, 8.2.7, 8.2.47\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 8.0.10 Requires-Python >=3.7,<=3.11; 8.0.11 Requires-Python >=3.7,<=3.11; 8.0.12 Requires-Python >=3.7,<=3.11; 8.0.13 Requires-Python >=3.7,<=3.11; 8.0.14 Requires-Python >=3.7,<=3.11; 8.0.15 Requires-Python >=3.7,<=3.11; 8.0.16 Requires-Python >=3.7,<=3.11; 8.0.17 Requires-Python >=3.7,<=3.11; 8.0.18 Requires-Python >=3.7,<=3.11; 8.0.19 Requires-Python >=3.7,<=3.11; 8.0.20 Requires-Python >=3.7,<=3.11; 8.0.21 Requires-Python >=3.7,<=3.11; 8.0.22 Requires-Python >=3.7,<=3.11; 8.0.23 Requires-Python >=3.7,<=3.11; 8.0.24 Requires-Python >=3.7,<=3.11; 8.0.25 Requires-Python >=3.7,<=3.11; 8.0.26 Requires-Python >=3.7,<=3.11; 8.0.27 Requires-Python >=3.7,<=3.11; 8.0.28 Requires-Python >=3.7,<=3.11; 8.0.29 Requires-Python >=3.7,<=3.11; 8.0.30 Requires-Python >=3.7,<=3.11; 8.0.31 Requires-Python >=3.7,<=3.11; 8.0.32 Requires-Python >=3.7,<=3.11; 8.0.33 Requires-Python >=3.7,<=3.11; 8.0.34 Requires-Python >=3.7,<=3.11; 8.0.7 Requires-Python >=3.7,<=3.11; 8.0.8 Requires-Python >=3.7,<=3.11; 8.0.9 Requires-Python >=3.7,<=3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement ultralytics==8.0.20 (from versions: 0.0.13, 0.0.14, 0.0.15, 0.0.16, 0.0.17, 0.0.18, 0.0.19, 0.0.20, 0.0.21, 0.0.22, 0.0.23, 0.0.24, 0.0.25, 0.0.26, 0.0.27, 0.0.28, 0.0.29, 0.0.30, 0.0.31, 0.0.32, 0.0.33, 0.0.34, 0.0.35, 0.0.36, 0.0.37, 0.0.38, 0.0.39, 0.0.40, 0.0.41, 0.0.42, 0.0.43, 0.0.44, 8.0.0, 8.0.1, 8.0.2, 8.0.3, 8.0.4, 8.0.5, 8.0.6, 8.0.35, 8.0.36, 8.0.37, 8.0.38, 8.0.39, 8.0.40, 8.0.41, 8.0.42, 8.0.43, 8.0.44, 8.0.45, 8.0.46, 8.0.47, 8.0.48, 8.0.49, 8.0.50, 8.0.51, 8.0.52, 8.0.53, 8.0.54, 8.0.55, 8.0.56, 8.0.57, 8.0.58, 8.0.59, 8.0.60, 8.0.61, 8.0.62, 8.0.63, 8.0.64, 8.0.65, 8.0.66, 8.0.67, 8.0.68, 8.0.69, 8.0.70, 8.0.71, 8.0.72, 8.0.73, 8.0.74, 8.0.75, 8.0.76, 8.0.77, 8.0.78, 8.0.79, 8.0.80, 8.0.81, 8.0.82, 8.0.83, 8.0.84, 8.0.85, 8.0.86, 8.0.87, 8.0.88, 8.0.89, 8.0.90, 8.0.91, 8.0.92, 8.0.93, 8.0.94, 8.0.95, 8.0.96, 8.0.97, 8.0.98, 8.0.99, 8.0.100, 8.0.101, 8.0.102, 8.0.103, 8.0.104, 8.0.105, 8.0.106, 8.0.107, 8.0.108, 8.0.109, 8.0.110, 8.0.111, 8.0.112, 8.0.113, 8.0.114, 8.0.115, 8.0.116, 8.0.117, 8.0.118, 8.0.119, 8.0.120, 8.0.121, 8.0.122, 8.0.123, 8.0.124, 8.0.125, 8.0.126, 8.0.127, 8.0.128, 8.0.130, 8.0.131, 8.0.132, 8.0.133, 8.0.134, 8.0.135, 8.0.136, 8.0.137, 8.0.138, 8.0.139, 8.0.140, 8.0.141, 8.0.142, 8.0.143, 8.0.144, 8.0.145, 8.0.146, 8.0.147, 8.0.148, 8.0.149, 8.0.150, 8.0.151, 8.0.152, 8.0.153, 8.0.154, 8.0.155, 8.0.156, 8.0.157, 8.0.158, 8.0.159, 8.0.160, 8.0.161, 8.0.162, 8.0.163, 8.0.164, 8.0.165, 8.0.166, 8.0.167, 8.0.168, 8.0.169, 8.0.170, 8.0.171, 8.0.172, 8.0.173, 8.0.175, 8.0.176, 8.0.178, 8.0.179, 8.0.180, 8.0.181, 8.0.182, 8.0.183, 8.0.184, 8.0.185, 8.0.186, 8.0.187, 8.0.188, 8.0.189, 8.0.190, 8.0.191, 8.0.192, 8.0.193, 8.0.194, 8.0.195, 8.0.196, 8.0.197, 8.0.198, 8.0.199, 8.0.200, 8.0.201, 8.0.202, 8.0.203, 8.0.204, 8.0.205, 8.0.206, 8.0.207, 8.0.208, 8.0.209, 8.0.210, 8.0.211, 8.0.212, 8.0.213, 8.0.214, 8.0.215, 8.0.216, 8.0.217, 8.0.218, 8.0.219, 8.0.220, 8.0.221, 8.0.222, 8.0.223, 8.0.224, 8.0.225, 8.0.226, 8.0.227, 8.0.228, 8.0.229, 8.0.230, 8.0.231, 8.0.232, 8.0.233, 8.0.234, 8.0.235, 8.0.236, 8.0.237, 8.0.238, 8.0.239, 8.1.0, 8.1.1, 8.1.2, 8.1.3, 8.1.4, 8.1.5, 8.1.6, 8.1.7, 8.1.8, 8.1.9, 8.1.10, 8.1.11, 8.1.12, 8.1.13, 8.1.14, 8.1.15, 8.1.16, 8.1.17, 8.1.18, 8.1.19, 8.1.20, 8.1.22, 8.1.23, 8.1.24, 8.1.25, 8.1.26, 8.1.27, 8.1.28, 8.1.29, 8.1.30, 8.1.32, 8.1.33, 8.1.34, 8.1.35, 8.1.36, 8.1.37, 8.1.38, 8.1.39, 8.1.40, 8.1.41, 8.1.42, 8.1.43, 8.1.44, 8.1.45, 8.1.46, 8.1.47, 8.2.0, 8.2.1, 8.2.2, 8.2.3, 8.2.4, 8.2.5, 8.2.6, 8.2.8, 8.2.9, 8.2.10, 8.2.11, 8.2.12, 8.2.13, 8.2.14, 8.2.15, 8.2.16, 8.2.17, 8.2.18, 8.2.19, 8.2.20, 8.2.21, 8.2.22, 8.2.23, 8.2.24, 8.2.25, 8.2.26, 8.2.27, 8.2.28, 8.2.29, 8.2.30, 8.2.31, 8.2.32, 8.2.33, 8.2.34, 8.2.35, 8.2.36, 8.2.37, 8.2.38, 8.2.39, 8.2.40, 8.2.41, 8.2.42, 8.2.43, 8.2.44, 8.2.45, 8.2.46, 8.2.48, 8.2.49, 8.2.50, 8.2.51, 8.2.52, 8.2.53, 8.2.54, 8.2.55, 8.2.56, 8.2.57, 8.2.58, 8.2.59, 8.2.60, 8.2.61, 8.2.62, 8.2.63, 8.2.64, 8.2.65, 8.2.66, 8.2.67, 8.2.68, 8.2.69, 8.2.70, 8.2.71, 8.2.72, 8.2.73, 8.2.74, 8.2.75, 8.2.76, 8.2.77, 8.2.78, 8.2.79, 8.2.80, 8.2.81, 8.2.82, 8.2.83, 8.2.84, 8.2.85, 8.2.86, 8.2.87, 8.2.88, 8.2.89, 8.2.90, 8.2.91, 8.2.92, 8.2.93, 8.2.94, 8.2.95, 8.2.96, 8.2.97, 8.2.98, 8.2.99, 8.2.100, 8.2.101, 8.2.102, 8.2.103, 8.3.0, 8.3.1, 8.3.2, 8.3.3, 8.3.4, 8.3.5, 8.3.6, 8.3.7, 8.3.8, 8.3.9, 8.3.10, 8.3.11, 8.3.12, 8.3.13, 8.3.14, 8.3.15, 8.3.16, 8.3.17, 8.3.18, 8.3.19, 8.3.20, 8.3.21, 8.3.22, 8.3.23, 8.3.24, 8.3.25, 8.3.26, 8.3.27, 8.3.28, 8.3.29, 8.3.30, 8.3.31, 8.3.32, 8.3.33, 8.3.34, 8.3.35, 8.3.36, 8.3.37, 8.3.38, 8.3.39, 8.3.40, 8.3.43, 8.3.44, 8.3.47, 8.3.48, 8.3.49, 8.3.50, 8.3.51, 8.3.52, 8.3.53, 8.3.54, 8.3.55, 8.3.56, 8.3.57, 8.3.58, 8.3.59, 8.3.60, 8.3.61, 8.3.62, 8.3.63, 8.3.64, 8.3.65, 8.3.66, 8.3.67, 8.3.68, 8.3.69, 8.3.70, 8.3.71, 8.3.72, 8.3.73, 8.3.74, 8.3.75, 8.3.76, 8.3.77, 8.3.78, 8.3.79, 8.3.80, 8.3.81, 8.3.82, 8.3.83, 8.3.84, 8.3.85, 8.3.86, 8.3.87, 8.3.88, 8.3.89, 8.3.90, 8.3.91, 8.3.92, 8.3.93, 8.3.94, 8.3.95, 8.3.96, 8.3.97, 8.3.98, 8.3.99, 8.3.100, 8.3.101, 8.3.102, 8.3.103, 8.3.104, 8.3.105, 8.3.106, 8.3.107, 8.3.108, 8.3.109, 8.3.110, 8.3.111, 8.3.112, 8.3.113, 8.3.114, 8.3.115, 8.3.116, 8.3.117, 8.3.118, 8.3.119, 8.3.120, 8.3.121, 8.3.122, 8.3.123, 8.3.124, 8.3.125, 8.3.126, 8.3.127, 8.3.128, 8.3.129, 8.3.130, 8.3.131, 8.3.132, 8.3.133, 8.3.134, 8.3.135, 8.3.136, 8.3.137, 8.3.138, 8.3.139, 8.3.140, 8.3.141, 8.3.142, 8.3.143, 8.3.144, 8.3.145, 8.3.146, 8.3.147, 8.3.148, 8.3.149, 8.3.150)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for ultralytics==8.0.20\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (2.7.0)\n",
            "Requirement already satisfied: torchvision in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (0.22.0)\n",
            "Requirement already satisfied: filelock in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (2025.5.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torch) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from triton==3.3.0->torch) (75.1.0)\n",
            "Requirement already satisfied: numpy in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torchvision) (2.2.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/sibghatullah/software_assigment/.conda/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.0.20\n",
        "!pip install torch torchvision\n",
        "!pip install -q kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "DC-J8kV7wRE8",
        "outputId": "3ac3d939-d818-4949-ffba-a65e7c807d36"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Upload kaggle.json manually\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Upload kaggle.json manually\n",
        "files.upload()\n",
        "\n",
        "# Setup Kaggle API\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qMB843-w5we",
        "outputId": "40c6aeac-c8af-42cc-a94c-c4a8353d6b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/alex000kim/magnetic-tile-surface-defects\n",
            "License(s): unknown\n",
            "magnetic-tile-surface-defects.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Dataset URL: https://www.kaggle.com/datasets/lakshaymiddha/crack-segmentation-dataset\n",
            "License(s): unknown\n",
            "crack-segmentation-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "replace magnetic_tile_dataset/MT_Blowhole/Imgs/exp1_num_108719.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d alex000kim/magnetic-tile-surface-defects\n",
        "!kaggle datasets download -d lakshaymiddha/crack-segmentation-dataset\n",
        "!unzip -q magnetic-tile-surface-defects.zip -d magnetic_tile_dataset\n",
        "!unzip -q crack-segmentation-dataset.zip -d crack_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBWEgOG1yal-",
        "outputId": "f6e0e58c-bd66-4cdb-d8f4-84d4f86f6454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace crack_dataset/crack_segmentation_dataset/images/CFD_001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace crack_dataset/crack_segmentation_dataset/images/CFD_002.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace crack_dataset/crack_segmentation_dataset/images/CFD_003.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace crack_dataset/crack_segmentation_dataset/images/CFD_004.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace crack_dataset/crack_segmentation_dataset/images/CFD_005.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace crack_dataset/crack_segmentation_dataset/images/CFD_005.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "crack_segmentation_dataset\n"
          ]
        }
      ],
      "source": [
        "!unzip -q crack-segmentation-dataset.zip -d crack_dataset\n",
        "!ls crack_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC8xvnWHyaie",
        "outputId": "6550593b-e4b1-4097-fe73-74d7ee68d4fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "images\tmasks  readme  test  train\n"
          ]
        }
      ],
      "source": [
        "!ls /content/crack_dataset/crack_segmentation_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjGbL3JEyagB",
        "outputId": "58a89c0a-c6aa-4a28-a0e2-773fa52c36c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.8/85.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics -q\n",
        "!pip install roboflow -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evh3hcPvxpzz",
        "outputId": "2efa172d-a4f3-4444-f9f9-51e6631f7027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MO6nya_Uz2sG"
      },
      "outputs": [],
      "source": [
        "img_dir = '/content/crack_dataset/crack_segmentation_dataset/images'\n",
        "mask_dir = '/content/crack_dataset/crack_segmentation_dataset/masks'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4texSoPK0Dqn"
      },
      "outputs": [],
      "source": [
        "# ğŸ”§ Run dataset preparation\n",
        "prepare_dataset(img_dir, mask_dir, '/content/yolo_crack')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1JrSsIK0JPm"
      },
      "outputs": [],
      "source": [
        "# ğŸ“ STEP 3: Create Data YAML File\n",
        "yaml_text = \"\"\"\n",
        "path: /content/yolo_crack\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "nc: 1\n",
        "names: ['crack']\n",
        "\"\"\"\n",
        "with open('/content/yolo_crack/data.yaml', 'w') as f:\n",
        "    f.write(yaml_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voIBWiWrKAAS"
      },
      "outputs": [],
      "source": [
        "# Install OpenCV for contour finding\n",
        "!pip install opencv-python -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiBFAmZd3YWh",
        "outputId": "3791e128-d457-4776-b598-007c0412dced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.146 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/yolo_crack/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=crack_segmentation6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/segment/crack_segmentation6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
            "YOLOv8n-seg summary: 151 layers, 3,263,811 parameters, 3,263,795 gradients, 12.1 GFLOPs\n",
            "\n",
            "Transferred 381/417 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1638.5Â±704.1 MB/s, size: 66.9 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_crack/labels/train... 7865 images, 1173 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9038/9038 [00:20<00:00, 451.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_crack/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 546.0Â±391.0 MB/s, size: 88.7 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_crack/labels/val... 1979 images, 281 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [00:08<00:00, 280.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_crack/labels/val.cache\n",
            "Plotting labels to runs/segment/crack_segmentation6/labels.jpg... \n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def prepare_dataset(img_dir, mask_dir, out_dir):\n",
        "    os.makedirs(f'{out_dir}/images/train', exist_ok=True)\n",
        "    os.makedirs(f'{out_dir}/images/val', exist_ok=True)\n",
        "    os.makedirs(f'{out_dir}/labels/train', exist_ok=True)\n",
        "    os.makedirs(f'{out_dir}/labels/val', exist_ok=True)\n",
        "\n",
        "    all_images = sorted(os.listdir(img_dir))\n",
        "    train_imgs, val_imgs = train_test_split(all_images, test_size=0.2, random_state=42)\n",
        "\n",
        "    def process(image_list, split):\n",
        "        for img_name in image_list:\n",
        "            img_path = os.path.join(img_dir, img_name)\n",
        "            mask_path = os.path.join(mask_dir, img_name)\n",
        "\n",
        "            # If no mask exists, skip this image\n",
        "            if not os.path.exists(mask_path):\n",
        "                continue\n",
        "\n",
        "            # Save image\n",
        "            shutil.copy(img_path, f\"{out_dir}/images/{split}/{img_name}\")\n",
        "\n",
        "            # Convert mask to binary format and load using OpenCV for contour finding\n",
        "            try:\n",
        "                import cv2\n",
        "                # Ensure mask is grayscale for findContours\n",
        "                mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
        "                # Threshold the mask to get a binary image\n",
        "                _, binary_mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "                # Find contours (hierarchy and contours)\n",
        "                # Use cv2.RETR_EXTERNAL to get only external contours\n",
        "                # Use cv2.CHAIN_APPROX_SIMPLE to compress horizontal, vertical, and diagonal segments\n",
        "                contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                if not contours:\n",
        "                    continue # skip empty mask if no contours are found\n",
        "\n",
        "                # Combine all contours into a single label line (assuming a single object class 'crack')\n",
        "                label_lines = []\n",
        "                h, w = mask.shape\n",
        "                for contour in contours:\n",
        "                     # Flatten contour points and normalize\n",
        "                    polygon_points = contour.flatten().tolist()\n",
        "\n",
        "                    # Normalize points by image dimensions\n",
        "                    normalized_polygon = [point / w if i % 2 == 0 else point / h for i, point in enumerate(polygon_points)]\n",
        "\n",
        "                    # Format for YOLO segmentation label: class_id x1 y1 x2 y2 ...\n",
        "                    # Check if polygon has enough points (at least 3 points for a polygon)\n",
        "                    if len(normalized_polygon) >= 6: # 3 points = 6 coordinates (x1, y1, x2, y2, x3, y3)\n",
        "                         label_lines.append(f\"0 \" + \" \".join(map(str, normalized_polygon)))\n",
        "\n",
        "\n",
        "                # Save label if there are any valid polygon lines\n",
        "                if label_lines:\n",
        "                    label_path = f\"{out_dir}/labels/{split}/{img_name.replace('.jpg', '.txt').replace('.png', '.txt')}\"\n",
        "                    with open(label_path, 'w') as f:\n",
        "                        for line in label_lines:\n",
        "                            f.write(line + \"\\n\")\n",
        "                else:\n",
        "                     # If no valid contours/polygons found, you might want to skip the image\n",
        "                     # or write an empty label file depending on desired behavior.\n",
        "                     # For now, we skip images with no valid polygons.\n",
        "                     print(f\"No valid contours found for {img_name}. Skipping label creation.\")\n",
        "                     os.remove(f\"{out_dir}/images/{split}/{img_name}\") # Remove the copied image as well\n",
        "                     continue\n",
        "\n",
        "\n",
        "            except ImportError:\n",
        "                print(\"Error: OpenCV not found. Segmentation label generation requires OpenCV. Install with '!pip install opencv-python'.\")\n",
        "                # Stop processing as correct labels cannot be generated\n",
        "                return\n",
        "\n",
        "\n",
        "    # Call the process function for train and validation sets\n",
        "    process(train_imgs, 'train')\n",
        "    process(val_imgs, 'val')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csx_8asGKKyl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "prepare_dataset(img_dir, mask_dir, '/content/yolo_crack')\n",
        "\n",
        "\n",
        "yaml_text = \"\"\"\n",
        "path: /content/yolo_crack\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "nc: 1\n",
        "names: ['crack']\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/yolo_crack/data.yaml', 'w') as f:\n",
        "    f.write(yaml_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLQgYZr21-62"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = YOLO(\"yolov8n-seg.pt\")  # you can use yolov8m-seg.pt or yolov8x-seg.pt for better results\n",
        "\n",
        "results = model.train(\n",
        "    data=\"/content/yolo_crack/data.yaml\",\n",
        "    epochs=20,\n",
        "    imgsz=640,\n",
        "    batch=8,\n",
        "    name=\"crack_segmentation\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
